{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sn\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from functools import reduce\n",
    "import random\n",
    "from numpy.linalg import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "val_errors1 = []\n",
    "test_errors1 = []\n",
    "\n",
    "SEED = 1000\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "df = pd.read_csv('Data\\\\X_train_raw.csv').T\n",
    "df_valid = pd.read_csv('Data\\\\X_valid_raw.csv').T\n",
    "df_test = pd.concat((pd.read_csv('Data\\\\X_test_raw_A.txt').T, pd.read_csv('Data\\\\X_test_raw_B.txt').T)).iloc[[0, 1, 2, 4, 5], :]\n",
    "rach_clusters = pd.read_csv('Data\\\\X_train_clusters.csv')\n",
    "Y_data = df.iloc[1:, -1].astype('float64')\n",
    "Y_copy = Y_data\n",
    "Y_valid_data = df_valid.iloc[1:, -1].astype('float64')\n",
    "Y_valid_copy = Y_valid_data\n",
    "\n",
    "common_IDs = reduce(np.intersect1d, (df.iloc[0, :-1].values, df_valid.iloc[0, :-1].values, df_test.iloc[0, :].values))\n",
    "\n",
    "idx = np.where(df.iloc[0, :].isin(common_IDs))[0]\n",
    "df = df.iloc[:, idx]\n",
    "idx_valid = np.where(df_valid.iloc[0, :].isin(common_IDs))[0]\n",
    "df_valid = df_valid.iloc[:, idx_valid]\n",
    "idx_test = np.where(df_test.iloc[0, :].isin(common_IDs))[0]\n",
    "df_test = df_test.iloc[:, idx_test]\n",
    "\n",
    "X_data = df.iloc[1:, :].astype('float64')\n",
    "X_ID = df.iloc[0, :]\n",
    "X_valid_data = df_valid.iloc[1:, :].astype('float64')\n",
    "X_valid_ID = df_valid.iloc[0, :]\n",
    "X_test_data = df_test.iloc[1:, :].astype('float64')\n",
    "X_test_ID = df_test.iloc[0, :]\n",
    "\n",
    "X_ID1 = np.argsort(X_ID)\n",
    "X_ID = X_ID.iloc[X_ID1]\n",
    "X_data = X_data.iloc[:, X_ID1]\n",
    "X_data.columns = X_ID\n",
    "X_ID1 = np.argsort(X_valid_ID)\n",
    "X_valid_ID = X_valid_ID.iloc[X_ID1]\n",
    "X_valid_data = X_valid_data.iloc[:, X_ID1]\n",
    "X_valid_data.columns = X_valid_ID\n",
    "X_ID1 = np.argsort(X_test_ID)\n",
    "X_test_ID = X_test_ID.iloc[X_ID1]\n",
    "X_test_data = X_test_data.iloc[:, X_ID1]\n",
    "X_test_data.columns = X_test_ID\n",
    "\n",
    "genes = ['AT1G13650.1',\n",
    "'AT3G55450.1',\n",
    "'AT1G02930.2',\n",
    "'AT1G79500.3',\n",
    "'AT5G24850.1',\n",
    "'AT5G06870.1',\n",
    "'AT5G41460.1',\n",
    "'AT5G01820.1',\n",
    "'AT4G08870.1',\n",
    "'AT1G75100.1',\n",
    "'AT2G29650.2',\n",
    "'AT5G06690.1',\n",
    "'AT3G17609.2',\n",
    "'AT4G15690.1',\n",
    "'AT1G06040.1'\n",
    "]\n",
    "\n",
    "X_data = X_data.loc[:, genes]\n",
    "X_valid_data = X_valid_data.loc[:, genes]\n",
    "X_test_data = X_test_data.loc[:, genes]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "n_folds = Y_data.shape[0]\n",
    "folds = KFold(n_splits=n_folds, random_state=SEED, shuffle=True)\n",
    "\n",
    "y_cos = -np.cos((2 * np.pi * Y_data.astype('float64') / 24)+(np.pi/2))\n",
    "y_sin = np.sin((2 * np.pi * Y_data.astype('float64') / 24)+(np.pi/2))\n",
    "\n",
    "Y_valid_cos = -np.cos((2 * np.pi * Y_valid_data.astype('float64') / 24)+(np.pi/2))\n",
    "Y_valid_sin = np.sin((2 * np.pi * Y_valid_data.astype('float64') / 24)+(np.pi/2))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_data)\n",
    "X_data = scaler.transform(X_data)\n",
    "X_valid_data = scaler.transform(X_valid_data)\n",
    "X_test_data = scaler.transform(X_test_data)\n",
    "\n",
    "def cyclical_loss(y_true, y_pred):\n",
    "    error = 0\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        error += np.arccos((y_true[i, :] @ y_pred[i, :]) / (norm(y_true[i, :]) * norm(y_pred[i, :])))\n",
    "    return error\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean((tf.math.acos(tf.matmul(y_true, tf.transpose(y_pred)) / ((tf.norm(y_true) * tf.norm(y_pred)) + tf.keras.backend.epsilon()))**2))\n",
    "\n",
    "adam = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(128, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(512, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(2, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=custom_loss, optimizer=adam)\n",
    "    return model\n",
    "\n",
    "Y_data = np.concatenate((y_cos.values.reshape(-1, 1), y_sin.values.reshape(-1, 1)), axis=1)\n",
    "Y_valid_data = np.concatenate((Y_valid_cos.values.reshape(-1, 1), Y_valid_sin.values.reshape(-1, 1)), axis=1)\n",
    "\n",
    "error = 0  # Initialise error\n",
    "all_preds = np.zeros((Y_data.shape[0], 2))  # Create empty array\n",
    "all_valid_preds = np.zeros((Y_valid_data.shape[0], 2))  # Create empty array\n",
    "early_stop = EarlyStopping(patience=50, restore_best_weights=True, monitor='val_loss', mode='min')\n",
    "\n",
    "\n",
    "def reset_seeds(reset_graph_with_backend=None, seed=0):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "valid_preds = []\n",
    "test_preds = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_data, Y_data)):\n",
    "    X_train, Y_train = X_data[train_idx], Y_data[train_idx]  # Define training data for this iteration\n",
    "    X_valid, Y_valid = X_data[valid_idx], Y_data[valid_idx]\n",
    "    model = larger_model()\n",
    "    model.fit(X_train.astype('float64'), Y_train.astype('float64'), validation_data=(X_valid.astype('float64'), Y_valid.astype('float64')),\n",
    "              batch_size=1, epochs=5000, callbacks=[early_stop])  # Fit the model on the training data\n",
    "    preds = normalize(model.predict(X_valid))  # Predict on the validation data\n",
    "    all_preds[valid_idx] = normalize(model.predict(X_valid))\n",
    "    all_valid_preds += (normalize(model.predict(X_valid_data)) / n_folds)\n",
    "    valid_preds.append(normalize(model.predict(X_valid_data)))\n",
    "    test_preds.append(normalize(model.predict(X_test_data)))\n",
    "    error += cyclical_loss(Y_valid.astype('float64'), preds.astype('float64'))  # Evaluate the predictions\n",
    "    print(cyclical_loss(Y_valid.astype('float64'), preds.astype('float64')) / Y_valid.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "angles = []\n",
    "for i in range(all_preds.shape[0]):\n",
    "    angles.append(math.atan2(all_preds[i, 0], all_preds[i, 1]) / math.pi * 12)\n",
    "\n",
    "for j in range(len(angles)):\n",
    "    if angles[j] < 0:\n",
    "        angles[j] = angles[j] + 24\n",
    "\n",
    "ax = sn.scatterplot(Y_data[:, 0], Y_data[:, 1])\n",
    "ax = sn.scatterplot(all_preds[:, 0], all_preds[:, 1])\n",
    "plt.show()\n",
    "angles_arr = np.vstack(angles)\n",
    "hour_pred = angles_arr\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "ax = sn.lineplot(np.arange(Y_copy.shape[0]), Y_copy)\n",
    "ax = sn.lineplot(np.arange(Y_copy.shape[0]), angles_arr.ravel())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "angles = []\n",
    "for i in range(all_preds.shape[0]):\n",
    "    angles.append(math.atan2(all_preds[i, 0], all_preds[i, 1]) / math.pi * 12)\n",
    "\n",
    "for j in range(len(angles)):\n",
    "    if angles[j] < 0:\n",
    "        angles[j] = angles[j] + 24\n",
    "\n",
    "\n",
    "valid_angles = []\n",
    "valid_preds = np.mean(valid_preds, axis=0)\n",
    "for i in range(valid_preds.shape[0]):\n",
    "    valid_angles.append(math.atan2(valid_preds[i, 0], valid_preds[i, 1]) / math.pi * 12)\n",
    "\n",
    "for j in range(len(valid_angles)):\n",
    "    if valid_angles[j] < 0:\n",
    "        valid_angles[j] = valid_angles[j] + 24\n",
    "valid_preds = normalize(valid_preds)\n",
    "ax = sn.scatterplot(Y_valid_data[:, 0], Y_valid_data[:, 1])\n",
    "ax = sn.scatterplot(valid_preds[:, 0], valid_preds[:, 1])\n",
    "plt.show()\n",
    "angles_arr_valid = np.vstack(valid_angles)\n",
    "hour_pred_valid = angles_arr_valid\n",
    "\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "ax = sn.lineplot(np.arange(Y_valid_copy.shape[0]), Y_valid_copy)\n",
    "ax = sn.lineplot(np.arange(Y_valid_copy.shape[0]), angles_arr_valid.ravel())\n",
    "plt.show()\n",
    "\n",
    "print(\"Average training error = {} minutes\".format(60 * 12 * cyclical_loss(Y_data.astype('float64'), all_preds.astype('float64')) / (Y_data.shape[0] * np.pi)))\n",
    "\n",
    "print(\"Average validation error = {} minutes\".format(60 * 12 * cyclical_loss(Y_valid_data.astype('float64'), valid_preds.astype('float64')) / (Y_valid_data.shape[0] * np.pi)))\n",
    "\n",
    "Y_copy1 = np.array([2, 5, 8, 11, 14, 17, 20, 23, 2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "test_angles = []\n",
    "test_preds_copy = test_preds\n",
    "test_preds = np.mean(test_preds, axis=0)\n",
    "for j in range(len(test_preds_copy)):\n",
    "    for i in range(test_preds.shape[0]):\n",
    "        test_preds_copy[j][i, 0] = math.atan2(test_preds_copy[j][i, 0], test_preds_copy[j][i, 1]) / math.pi * 12\n",
    "        if test_preds_copy[j][i, 0] < 0:\n",
    "            test_preds_copy[j][i, 0] += 24\n",
    "    test_preds_copy[j] = np.delete(test_preds_copy[j], 1, 1)\n",
    "\n",
    "for i in range(test_preds.shape[0]):\n",
    "    test_angles.append(math.atan2(test_preds[i, 0], test_preds[i, 1]) / math.pi * 12)\n",
    "for j in range(len(test_angles)):\n",
    "    if test_angles[j] < 0:\n",
    "        test_angles[j] = test_angles[j] + 24\n",
    "test_preds = normalize(test_preds)\n",
    "angles_arr_test = np.vstack(test_angles)\n",
    "hour_pred_test = angles_arr_test\n",
    "Y_test = np.array([12, 0, 12, 0])\n",
    "\n",
    "Y_test_cos = -np.cos((2 * np.pi * Y_test.astype('float64') / 24) + (np.pi / 2))\n",
    "Y_test_sin = np.sin((2 * np.pi * Y_test.astype('float64') / 24) + (np.pi / 2))\n",
    "Y_test_ang = np.concatenate((Y_test_cos.reshape(-1, 1), Y_test_sin.reshape(-1, 1)), axis=1)\n",
    "print(\"Average test error = {} minutes\".format(60 * 12 * cyclical_loss(Y_test_ang.astype('float64'), test_preds.astype('float64')) / (Y_test_ang.shape[0] * np.pi)))\n",
    "val_errors1.append(60 * 12 * cyclical_loss(Y_valid_data.astype('float64'), all_valid_preds.astype('float64')) / (Y_valid_data.shape[0] * np.pi))\n",
    "test_errors1.append(60 * 12 * cyclical_loss(Y_test_ang.astype('float64'), test_preds.astype('float64')) / (Y_test_ang.shape[0] * np.pi))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-c9f1ac05",
   "language": "python",
   "display_name": "PyCharm (HallCircadian)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}